(7729, 300, 8)
(7729,)
[1. 1. 1. ... 1. 1. 1.]
(6183, 300, 8)
weight0: 5.093080724876441
weight1: 0.5544296987087518
*****************************************
model_simple_ltsm
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 4)                 208       
                                                                 
 dense (Dense)               (None, 8)                 40        
                                                                 
 dense_1 (Dense)             (None, 16)                144       
                                                                 
 dense_2 (Dense)             (None, 4)                 68        
                                                                 
 dense_3 (Dense)             (None, 1)                 5         
                                                                 
=================================================================
Total params: 465
Trainable params: 465
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_one_layer_ltsm
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_1 (LSTM)               (None, 4)                 208       
                                                                 
 dense_4 (Dense)             (None, 8)                 40        
                                                                 
 dense_5 (Dense)             (None, 1)                 9         
                                                                 
=================================================================
Total params: 257
Trainable params: 257
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_one_layer_ltsm_v2
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_3 (LSTM)               (None, 4)                 208       
                                                                 
 dense_8 (Dense)             (None, 12)                60        
                                                                 
 dense_9 (Dense)             (None, 1)                 13        
                                                                 
=================================================================
Total params: 281
Trainable params: 281
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_bigger_lstm
Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_4 (LSTM)               (None, 8)                 544       
                                                                 
 dense_10 (Dense)            (None, 8)                 72        
                                                                 
 dense_11 (Dense)            (None, 2)                 18        
                                                                 
 dense_12 (Dense)            (None, 1)                 3         
                                                                 
=================================================================
Total params: 637
Trainable params: 637
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_bigger_bigger_lstm
Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_5 (LSTM)               (None, 12)                1008      
                                                                 
 dense_13 (Dense)            (None, 8)                 104       
                                                                 
 dense_14 (Dense)            (None, 1)                 9         
                                                                 
=================================================================
Total params: 1,121
Trainable params: 1,121
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_bigger_biggest_lstm
Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_6 (LSTM)               (None, 16)                1600      
                                                                 
 dense_15 (Dense)            (None, 4)                 68        
                                                                 
 dense_16 (Dense)            (None, 1)                 5         
                                                                 
=================================================================
Total params: 1,673
Trainable params: 1,673
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_double_stm
Model: "sequential_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_8 (LSTM)               (None, 300, 8)            544       
                                                                 
 lstm_9 (LSTM)               (None, 16)                1600      
                                                                 
 dense_20 (Dense)            (None, 8)                 136       
                                                                 
 dense_21 (Dense)            (None, 4)                 36        
                                                                 
 dense_22 (Dense)            (None, 1)                 5         
                                                                 
=================================================================
Total params: 2,321
Trainable params: 2,321
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_double_lstm_double_layers
Model: "sequential_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_10 (LSTM)              (None, 300, 8)            544       
                                                                 
 lstm_11 (LSTM)              (None, 16)                1600      
                                                                 
 dense_23 (Dense)            (None, 12)                204       
                                                                 
 dense_24 (Dense)            (None, 8)                 104       
                                                                 
 dense_25 (Dense)            (None, 4)                 36        
                                                                 
 dense_26 (Dense)            (None, 1)                 5         
                                                                 
=================================================================
Total params: 2,493
Trainable params: 2,493
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_bigger_lstm_v2
Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_7 (LSTM)               (None, 8)                 544       
                                                                 
 dense_17 (Dense)            (None, 12)                108       
                                                                 
 dense_18 (Dense)            (None, 36)                468       
                                                                 
 dense_19 (Dense)            (None, 1)                 37        
                                                                 
=================================================================
Total params: 1,157
Trainable params: 1,157
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
*****************************************
model_double_lstm_double_layers_more_nodes
Model: "sequential_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_12 (LSTM)              (None, 300, 8)            544       
                                                                 
 lstm_13 (LSTM)              (None, 16)                1600      
                                                                 
 dense_27 (Dense)            (None, 12)                204       
                                                                 
 dense_28 (Dense)            (None, 36)                468       
                                                                 
 dense_29 (Dense)            (None, 8)                 296       
                                                                 
 dense_30 (Dense)            (None, 1)                 9         
                                                                 
=================================================================
Total params: 3,121
Trainable params: 3,121
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>
-------------------------------
-------------------------------
optimizer: Adam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
-------------------------------
optimizer: Nadam<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>
-------------------------------
