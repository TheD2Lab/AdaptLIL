(13696, 300, 8)
(13696,)
epochs: 33
Shuffle: True
[1. 1. 1. ... 1. 1. 1.]
(10956, 300, 8)
weight0: 2.973941368078176
weight1: 1.5066006600660065
*****************************************
model_bigger_biggest_lstm_v16
Model: "sequential_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_16 (LSTM)              (None, 256)               271360    
                                                                 
 dense_56 (Dense)            (None, 16)                4112      
                                                                 
 dense_57 (Dense)            (None, 16)                272       
                                                                 
 dense_58 (Dense)            (None, 16)                272       
                                                                 
 dense_59 (Dense)            (None, 16)                272       
                                                                 
 dense_60 (Dense)            (None, 16)                272       
                                                                 
 dense_61 (Dense)            (None, 16)                272       
                                                                 
 dense_62 (Dense)            (None, 16)                272       
                                                                 
 dense_63 (Dense)            (None, 16)                272       
                                                                 
 dense_64 (Dense)            (None, 16)                272       
                                                                 
 dense_65 (Dense)            (None, 16)                272       
                                                                 
 dense_66 (Dense)            (None, 16)                272       
                                                                 
 dense_67 (Dense)            (None, 16)                272       
                                                                 
 dense_68 (Dense)            (None, 16)                272       
                                                                 
 dense_69 (Dense)            (None, 16)                272       
                                                                 
 dense_70 (Dense)            (None, 1)                 17        
                                                                 
=================================================================
Total params: 279,025
Trainable params: 279,025
Non-trainable params: 0
_________________________________________________________________
*****************************************
-------------------------------
unique model id: model_bigger_biggest_lstm_v16-Adagrad0,001
optimizer: Adagrad<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>
-------------------------------
loss : [1.3863070011138916, 1.386277437210083, 1.3862581253051758, 1.3862051963806152, 1.3861230611801147, 1.386016845703125, 1.3856399059295654, 1.385064721107483, 1.384675145149231, 1.3843411207199097, 1.3840688467025757, 1.3835428953170776, 1.3834021091461182, 1.3828657865524292, 1.3823187351226807, 1.3818352222442627, 1.3811237812042236, 1.3803458213806152, 1.379686951637268, 1.378767728805542, 1.3777283430099487, 1.3770384788513184, 1.375825047492981, 1.3747339248657227, 1.373849630355835, 1.3723562955856323, 1.3715804815292358, 1.3697971105575562, 1.368345856666565, 1.36641526222229, 1.3648186922073364, 1.3622288703918457, 1.3599778413772583]
tp : [93.0, 0.0, 0.0, 315.0, 196.0, 870.0, 2318.0, 2467.0, 2553.0, 2442.0, 2392.0, 2592.0, 2424.0, 2500.0, 2731.0, 2917.0, 2969.0, 2918.0, 3004.0, 3141.0, 3210.0, 3072.0, 3077.0, 3198.0, 3259.0, 3477.0, 3216.0, 3132.0, 3296.0, 3225.0, 3100.0, 3289.0, 3230.0]
tn : [3631.0, 3684.0, 3684.0, 3585.0, 3643.0, 3483.0, 2960.0, 2959.0, 2968.0, 3003.0, 3025.0, 2972.0, 3066.0, 3029.0, 2926.0, 2833.0, 2860.0, 2884.0, 2874.0, 2823.0, 2800.0, 2857.0, 2867.0, 2853.0, 2789.0, 2699.0, 2828.0, 2886.0, 2782.0, 2864.0, 2939.0, 2888.0, 2955.0]
accuracy : [0.3399050831794739, 0.3362541198730469, 0.3362541198730469, 0.3559693396091461, 0.3504016101360321, 0.3973165452480316, 0.4817451536655426, 0.4952537417411804, 0.5039247870445251, 0.4969879388809204, 0.494432270526886, 0.5078495740890503, 0.5010952949523926, 0.5046550035476685, 0.516338050365448, 0.5248265862464905, 0.5320372581481934, 0.5295728445053101, 0.5365096926689148, 0.5443592667579651, 0.5485578775405884, 0.5411646366119385, 0.5425337553024292, 0.5523000955581665, 0.5520262718200684, 0.5637093782424927, 0.5516611933708191, 0.5492880344390869, 0.5547645092010498, 0.5557685494422913, 0.5512048006057739, 0.5638006329536438, 0.5645308494567871]
precision : [0.6369863152503967, 0.0, 0.0, 0.760869562625885, 0.8270041942596436, 0.8123249411582947, 0.76199871301651, 0.7728696465492249, 0.7809727787971497, 0.7819404602050781, 0.7840052247047424, 0.7845036387443542, 0.7968441843986511, 0.7923930287361145, 0.7827457785606384, 0.7741507291793823, 0.7827576994895935, 0.7848305702209473, 0.7876245379447937, 0.7848575711250305, 0.7840742468833923, 0.7878943085670471, 0.7901900410652161, 0.7937453389167786, 0.7845450043678284, 0.779246985912323, 0.7897838950157166, 0.7969465851783752, 0.785135805606842, 0.7972806096076965, 0.8062418699264526, 0.8051407337188721, 0.8158625960350037]
val_loss : [0.6934787631034851, 0.6934940218925476, 0.6934559345245361, 0.6934755444526672, 0.6934268474578857, 0.6931734085083008, 0.6931614279747009, 0.6930985450744629, 0.6929770708084106, 0.6927131414413452, 0.6924580931663513, 0.692518413066864, 0.692660927772522, 0.6924498081207275, 0.692084550857544, 0.6920121908187866, 0.6914324164390564, 0.6908731460571289, 0.6909912824630737, 0.690717875957489, 0.6907709240913391, 0.6900811791419983, 0.6901233792304993, 0.6899966597557068, 0.6878179907798767, 0.690104603767395, 0.6885491013526917, 0.6871896982192993, 0.6860747337341309, 0.6862409710884094, 0.6845095157623291, 0.684521496295929, 0.6834442615509033]
val_tp : [0.0, 0.0, 0.0, 0.0, 135.0, 505.0, 584.0, 576.0, 568.0, 650.0, 675.0, 638.0, 565.0, 665.0, 745.0, 733.0, 738.0, 788.0, 773.0, 782.0, 740.0, 769.0, 779.0, 774.0, 867.0, 722.0, 776.0, 867.0, 856.0, 792.0, 841.0, 798.0, 881.0]
val_tn : [909.0, 909.0, 909.0, 909.0, 894.0, 740.0, 717.0, 737.0, 749.0, 729.0, 720.0, 738.0, 768.0, 729.0, 678.0, 703.0, 705.0, 689.0, 702.0, 697.0, 716.0, 709.0, 702.0, 710.0, 655.0, 733.0, 721.0, 664.0, 684.0, 726.0, 718.0, 737.0, 675.0]
val_accuracy : [0.33175182342529297, 0.33175182342529297, 0.33175182342529297, 0.33175182342529297, 0.3755474388599396, 0.4543795585632324, 0.47481751441955566, 0.47919708490371704, 0.4806569218635559, 0.5032846927642822, 0.5091241002082825, 0.5021897554397583, 0.48649635910987854, 0.5087591409683228, 0.5193430781364441, 0.5240876078605652, 0.5266423225402832, 0.5390511155128479, 0.5383211970329285, 0.5397810339927673, 0.5313868522644043, 0.5394160747528076, 0.5405109524726868, 0.5416058301925659, 0.5554744601249695, 0.5310218930244446, 0.546350359916687, 0.5587591528892517, 0.5620437860488892, 0.5540146231651306, 0.5689781308174133, 0.5602189898490906, 0.5678831934928894]
val_precision : [0.0, 0.0, 0.0, 0.0, 0.8999999761581421, 0.7492581605911255, 0.7525773048400879, 0.7700534462928772, 0.7802197933197021, 0.7831325531005859, 0.78125, 0.7886279225349426, 0.8002833127975464, 0.7869822382926941, 0.7633196711540222, 0.7806176543235779, 0.7834395170211792, 0.7817460298538208, 0.7887755036354065, 0.786720335483551, 0.7931404113769531, 0.7936016321182251, 0.7900608777999878, 0.7954779267311096, 0.7734165787696838, 0.8040089011192322, 0.8049792647361755, 0.7796762585639954, 0.7918593883514404, 0.8123077154159546, 0.8149224519729614, 0.8226804137229919, 0.7901345491409302]

[[2140 1643]
 [ 332  344]]
model_bigger_biggest_lstm_v16-Adagrad0,001
[[2140 1643]
 [ 332  344]]
tn: %: 0.5088757396449705 tp %: 0.5656886069257203
